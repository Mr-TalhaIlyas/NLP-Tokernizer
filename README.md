# NLP-Tokernizer
A subword tokenizer is that it interpolates between word-based and character-based tokenization. Common words get a slot in the vocabulary, but the tokenizer can fall back to word pieces and individual characters for unknown words.


### Sample Datasets

TED talk sampel datasets can be downlaoded from

https://github.com/neulab/word-embeddings-for-nmt
